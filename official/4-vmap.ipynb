{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([11., 20., 29.], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.arange(5)\n",
    "w = jnp.array([2.0, 3.0, 4.0])\n",
    "\n",
    "\n",
    "def convolve(x, w):\n",
    "    output = []\n",
    "    for i in range(1, len(x) - 1):\n",
    "        output.append(jnp.dot(x[i - 1 : i + 2], w))\n",
    "    return jnp.array(output)\n",
    "\n",
    "\n",
    "convolve(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = jnp.stack([x, x])\n",
    "ws = jnp.stack([w, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 20., 29.],\n",
       "       [11., 20., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manually_batched_convolve(xs, ws):\n",
    "    output = []\n",
    "    for i in range(xs.shape[0]):\n",
    "        output.append(convolve(xs[i], ws[i]))\n",
    "    return jnp.stack(output)\n",
    "\n",
    "\n",
    "manually_batched_convolve(xs, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces the correct result, however it is not very efficient.\n",
    "\n",
    "In order to batch the computation efficiently, you would normally have to rewrite the function manually to ensure it is done in vectorized form. This is not particularly difficult to implement, but does involve changing how the function treats indices, axes, and other parts of the input.\n",
    "\n",
    "For example, we could manually rewrite `convolve()` to support vectorized computation across the batch dimension as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_vectorized_convolve(xs, ws):\n",
    "    output = []\n",
    "    for i in range(1, xs.shape[-1] - 1):\n",
    "        output.append(jnp.sum(xs[:, i - 1 : i + 2] * ws, axis=1))\n",
    "    return jnp.stack(output, axis=1)\n",
    "\n",
    "\n",
    "manually_vectorized_convolve(xs, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 20., 29.],\n",
       "       [11., 20., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_batch_convolve = jax.vmap(convolve)\n",
    "\n",
    "auto_batch_convolve(xs, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the batch dimension is not the first, you may use the `in_axes` and `out_axes` arguments to specify the location of the batch dimension in inputs and outputs. These may be an integer if the batch axis is the same for all inputs and outputs, or lists, otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 11.],\n",
       "       [20., 20.],\n",
       "       [29., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_batch_convolve_v2 = jax.vmap(convolve, in_axes=1, out_axes=1)\n",
    "\n",
    "xst = jnp.transpose(xs)\n",
    "wst = jnp.transpose(ws)\n",
    "\n",
    "auto_batch_convolve_v2(xst, wst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.vmap()` also supports the case where only one of the arguments is batched: for example, if you would like to convolve to a single set of weights `w` with a batch of vectors `x`; in this case the `in_axes` argument can be set to `None`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 20., 29.],\n",
       "       [11., 20., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_convolve_v3 = jax.vmap(convolve, in_axes=[0, None])\n",
    "\n",
    "batch_convolve_v3(xs, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all JAX transformations, `jax.jit()` and `jax.vmap()` are designed to be composable, which means you can wrap a vmapped function with `jit`, or a jitted function with `vmap`, and everything will work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[11., 20., 29.],\n",
       "       [11., 20., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jitted_batch_convolve = jax.jit(auto_batch_convolve)\n",
    "\n",
    "jitted_batch_convolve(xs, ws)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
